<a href="https://www.doji-tech.com/">
  <img src="https://www.doji-tech.com/assets/favicon.ico" alt="doji logo" title="Doji" align="right" height="70" />
</a>

# Midas
Monocular Depth Estimation with Unity Sentis using [MiDaS](https://github.com/isl-org/MiDaS)[^1] models

[**Asset Store**](https://assetstore.unity.com/packages/tools/ai-ml-integration/midas-monocular-depth-estimation-268501?aid=1101l3w5RJ&pubref=gh)

[OpenUPM] · [Documentation] · [Forum] · [Hugging Face]

This project is dual-licensed. You can either get it here on GitHub under the MIT License, or — if you find it useful and want to support the development — for a small price on the [Unity Asset Store].

![chromatic_GH_wide](https://docs.doji-tech.com/com.doji.midas/images/model_samples.webp)

## Usage

Please refer to the [Documentation] for usage guides.

## References

[^1]: [René Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun. Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer. IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 44, no. 3, 2022](https://github.com/isl-org/MiDaS)

[Midas]: https://github.com/isl-org/MiDaS
[Unity Asset Store]: https://assetstore.unity.com/packages/tools/ai-ml-integration/midas-monocular-depth-estimation-268501?aid=1101l3w5RJ&pubref=gh
[OpenUPM]: https://openupm.com/packages/com.doji.midas
[Documentation]: https://docs.doji-tech.com/com.doji.midas
[Forum]: https://forum.unity.com/threads/released-midas-monocular-depth-estimation.1539250/
[Hugging Face]: https://huggingface.co/julienkay/sentis-MiDaS
